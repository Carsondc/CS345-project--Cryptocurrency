{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d95890a",
   "metadata": {},
   "source": [
    "### The Linear Regression File "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7f848",
   "metadata": {},
   "source": [
    "# number of days since start | open | high | low | close | sma(10 days) | golden cross | death cross\n",
    "#          0                 |  1   |  2   |  3  |   4   |      5       |      6       |      7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb54e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e62cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9604605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files\n",
      "Loading 1INCH.csv...\n",
      "Loading AAVE.csv...\n",
      "Loading ADA.csv...\n",
      "Loading ALGO.csv...\n",
      "Loading AMP.csv...\n",
      "The columns are: (number of days since start,open,high,low,close,sma(10 days),golden cross, death cross)\n"
     ]
    }
   ],
   "source": [
    "import preprocess\n",
    "\n",
    "files = preprocess.potential_files[:5]\n",
    "\n",
    "preprocess_class_instantiation = preprocess.preprocess(files, 7)\n",
    "\n",
    "datasets = preprocess_class_instantiation.generate_data()\n",
    "\n",
    "file_for_given_row = {}\n",
    "for index, crypto_name in enumerate(files):\n",
    "    file_for_given_row[crypto_name] = index\n",
    "    # if crypto_name == '1INCH.csv':\n",
    "    # print(f'index : {index} -- crypto_name : {crypto_name}')\n",
    "\n",
    "# for key, val in file_for_given_row.items():\n",
    "#     print(key, val)\n",
    "\n",
    "# print(file_for_given_row['1INCH.csv'])\n",
    "\n",
    "# for f in files:\n",
    "#     print(f\"https://www.kaggle.com/datasets/svaningelgem/crypto-currencies-daily-prices?resource=download&select={f}\")\n",
    "\n",
    "# print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1aece52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### NESTED LIST RETRIEVAL OF X FOR GIVEN CURRENCY ##################################################################################\n",
    "# filename = '1INCH.csv'\n",
    "\n",
    "def get_X_or_y_for_given_currency(currency, x_or_y):\n",
    "        processed_file_dict = {}\n",
    "        if (x_or_y == 'X') or (x_or_y == 'x'):\n",
    "            x_or_y = 0\n",
    "        elif (x_or_y == 'Y') or (x_or_y == 'y'):\n",
    "            x_or_y = 1\n",
    "        else:\n",
    "            print(f'x_or_y needs to be x or y')\n",
    "        row = file_for_given_row[currency]\n",
    "        \n",
    "        for csv_name, row in file_for_given_row.items():\n",
    "            if currency == csv_name:\n",
    "                processed_file_dict[csv_name] = datasets[row][x_or_y]\n",
    "                return processed_file_dict[csv_name]\n",
    "    \n",
    "# get_X_or_y_for_given_currency(filename, 'X')\n",
    "# get_X_or_y_for_given_currency(filename, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201eb391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_currency(currency_we_want_to_look_at):\n",
    "\t\n",
    "\n",
    "\tX = get_X_or_y_for_given_currency(currency_we_want_to_look_at, 'X')\n",
    "\ty = get_X_or_y_for_given_currency(currency_we_want_to_look_at, 'y')\n",
    "\n",
    "\treturn X, y\n",
    "\n",
    "currency_we_want_to_look_at = '1INCH.csv'\n",
    "# currency_we_want_to_look_at = 'AAVE.csv'\n",
    "# currency_we_want_to_look_at = 'ADA.csv'\n",
    "# currency_we_want_to_look_at = 'ALGO.csv'\n",
    "# currency_we_want_to_look_at = 'AMP.csv'\n",
    "X, y = the_currency(currency_we_want_to_look_at)\n",
    "\n",
    "# print(\"first row of X:\", X[0])\n",
    "# print(\"first 10 closes from X[:,4]:\", X[:10, 4])\n",
    "# print(\"first 10 y values:\", y[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735111d",
   "metadata": {},
   "source": [
    "# Multivariable Linear Regression Section\n",
    "### 1) find the most sig weihts (features) and dicuss what that means\n",
    "### 2) get the LOBF to be fitted to the data trajectory\n",
    "### 3) discuss various errors measured against the data and what that tells us about the real values vs our pred values ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f143e",
   "metadata": {},
   "source": [
    "### get a function that fits the line better \n",
    "\n",
    "##### A model that is overfitting has the following characteristics:\n",
    "\n",
    "###### - It matches the training set too closely.\n",
    "###### - It does well on the training data, but doesn't *generalize* to new data.  In other words, it performs poorly on independent test data.\n",
    "###### - It learns from the noise in the data, rather than the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f4c239",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 208\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction_vals, train_and_test_errors_at_given_degree, best_graph, RMSE_bar_chart, MAE_bar_chart\n\u001b[32m    206\u001b[39m pred_x_at_this_point = [\u001b[32m20\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m prediction_vals, train_and_test_errors_at_given_degree, best_graph, RMSE_bar_chart, MAE_bar_chart =  \u001b[43mpredictionVals_Plot_DictOfErrors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_x_at_this_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(prediction_vals))\n\u001b[32m    211\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(train_and_test_errors_at_given_degree))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 204\u001b[39m, in \u001b[36mpredictionVals_Plot_DictOfErrors\u001b[39m\u001b[34m(prediction_points)\u001b[39m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best_fit_plot, axs[\u001b[32m0\u001b[39m], axs[\u001b[32m1\u001b[39m]\n\u001b[32m    202\u001b[39m     best_graph, RMSE_bar_chart, MAE_bar_chart = barchart_and_graph()\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprediction_vals\u001b[49m, train_and_test_errors_at_given_degree, best_graph, RMSE_bar_chart, MAE_bar_chart\n",
      "\u001b[31mNameError\u001b[39m: name 'prediction_vals' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # ## number of days since start | open | high | low | close | sma(10 days) | golden cross | death cross\n",
    "# # ##          0                 |  1   |  2   |  3  |   4   |      5       |      6       |      7\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X0 = X[:, [0]]\n",
    "\n",
    "def get_prediction_at_given_x(pipeln, feature_indecies, prediction_points, ax):\n",
    "    preds = []\n",
    "    for h in prediction_points:\n",
    "        x_row = X[h, feature_indecies].reshape(1, -1)\n",
    "        y_pred_at_this_point = pipeln.predict(x_row)[0]\n",
    "        preds.append(y_pred_at_this_point)\n",
    "        # print(y_pred_at_this_point)\n",
    "        # print(X[h,0])\n",
    "        # print(h)\n",
    "        ax.plot(h, y_pred_at_this_point, marker='x', color='orange', label=f'prediction at {h} : {y_pred_at_this_point}', markersize=12)\n",
    "    return preds\n",
    "\n",
    "def predictionVals_Plot_DictOfErrors(prediction_points):\n",
    "    train_and_test_errors_at_given_degree = {}\n",
    "    polynomial_degrees = [1,2,3,4,5,6,7,8]\n",
    "    feature_indecies = [0,1,2,3,4,5,6,7]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "    alphas_to_test = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "    for i in range(len(polynomial_degrees)):\n",
    "        \n",
    "        ### NOTE: make the line eq a mutlti-var lin eq\n",
    "        polynomial_features_train = PolynomialFeatures(degree=polynomial_degrees[i], include_bias=False)\n",
    "        \n",
    "        ### NOTE: apply lin reg to the new mutlti-var lin eq\n",
    "        linear_regression_model_train = RidgeCV(alphas=alphas_to_test)# ridge adds l2 to regression to shrink the coefficients of the loss funciton to prevent overfitting\n",
    "        \n",
    "        ### NOTE: instantiate the pipline\n",
    "        pipeline_on_training_data = Pipeline([(\"polynomial_features\", polynomial_features_train), (\"linear_regression\", linear_regression_model_train)])\n",
    "        \n",
    "        ### NOTE: apply the pipline\n",
    "        \n",
    "        ##spilt\n",
    "        #                                                                                                                       \n",
    "        X_train2, X_test2, y_train2, y_test2 = train_test_split(X[:, feature_indecies], y, test_size=0.3, random_state=67, shuffle=True)\n",
    "\n",
    "        ##fit \n",
    "        pipeline_on_training_data.fit(X_train2, y_train2)\n",
    "        \n",
    "        ##predict on train and test\n",
    "        y_pred_train2 = pipeline_on_training_data.predict(X_train2)\n",
    "        y_pred_test2 = pipeline_on_training_data.predict(X_test2)\n",
    "        \n",
    "        train_MAE2 = mean_absolute_error(y_train2, y_pred_train2)\n",
    "        test_MAE2 = mean_absolute_error(y_test2, y_pred_test2)\n",
    "        \n",
    "        train_MSE2 = mean_squared_error(y_train2, y_pred_train2)\n",
    "        test_MSE2 = mean_squared_error(y_test2, y_pred_test2)\n",
    "\n",
    "        train_RMSE2 = np.sqrt(train_MSE2)\n",
    "        test_RMSE2 = np.sqrt(test_MSE2)\n",
    "        \n",
    "        naive_MAE2 = mean_absolute_error(y_test2, np.full(y_test2.shape, np.mean(y_train2)))\n",
    "        \n",
    "        # if polynomial_degrees[i] == 1:\n",
    "        #     ax = plt.subplot(1,1,1)\n",
    "        #     plt.xlabel('x')\n",
    "        #     plt.ylabel('y')\n",
    "        #     ax.scatter(X_test2[:,0], y_test2, color=\"red\", label='test')\n",
    "            \n",
    "        #     max_bound = prediction_points[0]\n",
    "        #     max_bound = max_bound*10\n",
    "            \n",
    "        #     ax.set_xlim(0,max_bound)\n",
    "        #     ax.set_ylim(0,max_bound)\n",
    "            \n",
    "        #     # LOBF_X = pipeline1.predict(X[:, feature_indecies])\n",
    "        #     LOBF_train_set = pipeline_on_training_data.predict(X[:, feature_indecies])\n",
    "            \n",
    "        #     # ax.plot(X0, LOBF_X, label=\"model trained on all data\", color=\"purple\", linewidth=2) data leakage \n",
    "        #     ax.plot(X0, LOBF_train_set, label=\"model trained on training data\", color=\"green\", linewidth=3)\n",
    "            \n",
    "        #     prediction_vals = get_prediction_at_given_x(pipeline_on_training_data, feature_indecies, prediction_points, ax)\n",
    "            \n",
    "        #     ax.set_xlabel(f'days in the future')\n",
    "            \n",
    "        #     ax.set_ylabel('value of the target')\n",
    "        #     ax.legend(loc='center left', bbox_to_anchor=(0.5, -0.5), ncol=1, fontsize=8, frameon=False, borderaxespad=10, labelspacing=2)\n",
    "        #     plt.title(f\"Degree {polynomial_degrees[i]}\")\n",
    "        #     ax.grid() \n",
    "            \n",
    "        #     best_fit_plot = plt.gcf()\n",
    "###############################################################################################################################################################################\n",
    "        train_and_test_errors_at_given_degree[i] = {\n",
    "            \n",
    "            'train' : {\n",
    "                'MAE' : train_MAE2,\n",
    "                'MSE' : train_MSE2,\n",
    "                'RMSE' : train_RMSE2\n",
    "            },\n",
    "            'test' : {\n",
    "                'MAE' : test_MAE2,\n",
    "                'MSE' : test_MSE2,\n",
    "                'RMSE' : test_RMSE2\n",
    "            },\n",
    "            'naive_MAE' : naive_MAE2\n",
    "        }\n",
    "        \n",
    "    def barchart_and_graph():\n",
    "        rows = []\n",
    "        for i, deg in enumerate(polynomial_degrees):\n",
    "            m = train_and_test_errors_at_given_degree[i]\n",
    "            rows.append({\n",
    "                'deg' : deg,\n",
    "                'train_RMSE' : m['train']['RMSE'],\n",
    "                'test_RMSE' : m['test']['RMSE'],\n",
    "                'train_MAE' : m['train']['MAE'],\n",
    "                'test_MAE' : m['test']['MAE'],\n",
    "                'naiveMAE' : m['naive_MAE']\n",
    "\n",
    "            })\n",
    "        # make a dataframe of the rows list using .sort_values by degree\n",
    "        metrics_df = pd.DataFrame(rows).sort_values(['test_RMSE', 'test_MAE'], ascending=True)\n",
    "\n",
    "        # print(metrics_df)\n",
    "        # pick best degree (row) by the lowest test RMSE key then test MAE key then initialize the \n",
    "        best_row = metrics_df.sort_values(['test_RMSE', 'test_MAE'], ascending=True).iloc[0]  ## used AI to learn about the approach of the tie break (since RMSE punishes )\n",
    "        # print(best_row)\n",
    "        best_degree = int(best_row['deg'])\n",
    "        # print(best_degree)\n",
    "    \n",
    "        plt.figure(figsize=(20,10))\n",
    "        if polynomial_degrees[i] == best_degree:\n",
    "            plt = plt.subplot(1,1,1)\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('y')\n",
    "            plt.scatter(X_test2[:,0], y_test2, color=\"red\", label='test')\n",
    "            \n",
    "            max_bound = prediction_points[0]\n",
    "            max_bound = max_bound+20\n",
    "        \n",
    "            plt.set_xlim(0,max_bound)\n",
    "            plt.set_ylim(0,max_bound)\n",
    "            \n",
    "            # LOBF_X = pipeline1.predict(X[:, feature_indecies])\n",
    "            LOBF_train_set = pipeline_on_training_data.predict(X[:, feature_indecies])\n",
    "            \n",
    "            # ax.plot(X0, LOBF_X, label=\"model trained on all data\", color=\"purple\", linewidth=2) data leakage \n",
    "            plt.plot(X0, LOBF_train_set, label=\"model trained on training data\", color=\"green\", linewidth=3)\n",
    "            \n",
    "            prediction_vals = get_prediction_at_given_x(pipeline_on_training_data, feature_indecies, prediction_points, ax)\n",
    "            \n",
    "            plt.set_xlabel(f'days in the future')\n",
    "            \n",
    "            plt.set_ylabel('value of the target')\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(0.5, -0.5), ncol=1, fontsize=8, frameon=False, borderaxespad=10, labelspacing=2)\n",
    "            plt.title(f\"Degree {polynomial_degrees[i]}\")\n",
    "            plt.grid() \n",
    "            \n",
    "            best_fit_plot = plt.gcf()\n",
    "        # https://www.youtube.com/watch?v=G0Olm-4CP50\n",
    "        # build a data frame of the collected errors \n",
    "        \n",
    "\n",
    "        # plot bar charts t ocompare errors accross degrees \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(18, 4))\n",
    "            # - axs 0, 1, and 2 is the bar of the degree key for x and te train/test_error key for y, make sure to use aplpha to make it more transparent\n",
    "        # axs[0].bar(metrics_df['deg'], metrics_df['train_RMSE'], label='train_RMSE', alpha=1)\n",
    "        # axs[0].bar(metrics_df['deg'], metrics_df['test_RMSE'], label='test_RMSE', alpha=0.5)\n",
    "        # axs[0].set_title('RMSE for each degree')\n",
    "        # axs[0].set_xlabel('degree')\n",
    "        # axs[0].set_ylabel('RMSE')\n",
    "        # axs[0].legend()\n",
    "\n",
    "        # axs[1].bar(metrics_df['deg'], metrics_df['train_MAE'], label='train_MAE', alpha=1)\n",
    "        # axs[1].bar(metrics_df['deg'], metrics_df['test_MAE'], label='test_MAE', alpha=0.5)\n",
    "        # axs[1].set_title('MAE for each degree')\n",
    "        # axs[1].set_xlabel('degree')\n",
    "        # axs[1].set_ylabel('MAE')\n",
    "        # axs[1].legend()\n",
    "\n",
    "        axs[0].bar(best_row['deg'], best_row['train_RMSE'], label='train_RMSE', alpha=1)\n",
    "        axs[0].bar(best_row['deg'], best_row['test_RMSE'], label='test_RMSE', alpha=0.5)\n",
    "        axs[0].bar(best_row['deg'], best_row['naiveMAE'], label='naiveMAE', alpha=0.25)\n",
    "        axs[0].set_title(f'RMSE at best degree {best_degree}')\n",
    "        axs[0].set_xlabel(f\"{best_degree}\\nbest RMSE error on the test set\\n{best_row['test_RMSE']}\")\n",
    "        axs[0].set_xticks([])\n",
    "        axs[0].set_ylabel('RMSE value')\n",
    "        axs[0].legend()\n",
    "\n",
    "        axs[1].bar(best_row['deg'], best_row['train_MAE'], label='train_MAE', alpha=1)\n",
    "        axs[1].bar(best_row['deg'], best_row['test_MAE'], label='test_MAE', alpha=0.5)\n",
    "        axs[1].bar(best_row['deg'], best_row['naiveMAE'], label='naiveMAE', alpha=0.25)\n",
    "        axs[1].set_title(f'MAE at best degree {best_degree}')\n",
    "        axs[1].set_xlabel(f\"{best_degree}\\nbest MAE error on the test set\\n{best_row['test_MAE']}\")\n",
    "        axs[1].set_xticks([])\n",
    "        axs[1].set_ylabel('MAE value')\n",
    "        axs[1].legend()\n",
    "\n",
    "        return best_fit_plot, axs[0], axs[1]\n",
    "        \n",
    "        best_graph, RMSE_bar_chart, MAE_bar_chart = barchart_and_graph()\n",
    "        \n",
    "    return prediction_vals, train_and_test_errors_at_given_degree, best_graph, RMSE_bar_chart, MAE_bar_chart\n",
    "\n",
    "pred_x_at_this_point = [20]\n",
    "\n",
    "prediction_vals, train_and_test_errors_at_given_degree, best_graph, RMSE_bar_chart, MAE_bar_chart =  predictionVals_Plot_DictOfErrors(pred_x_at_this_point)\n",
    "\n",
    "print(type(prediction_vals))\n",
    "print(type(train_and_test_errors_at_given_degree))\n",
    "print(type(best_graph))\n",
    "print(type(RMSE_bar_chart))\n",
    "print(type(MAE_bar_chart))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0adf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_deg = [1,2,3,4,5,6,7,8]\n",
    "for i in range(len(poly_deg)):\n",
    "    \n",
    "    print(f\"degree {i} train MAE : {train_and_test_errors_at_given_degree[i]['train']['MAE']}\")\n",
    "    print(f\"degree {i} test MAE : {train_and_test_errors_at_given_degree[i]['test']['MAE']}\")\n",
    "    \n",
    "    print(f\"degree {i} train MSE : {train_and_test_errors_at_given_degree[i]['train']['MSE']}\")\n",
    "    print(f\"degree {i} test MSE : {train_and_test_errors_at_given_degree[i]['test']['MSE']}\")\n",
    "    \n",
    "    print(f\"degree {i} train RMSE : {train_and_test_errors_at_given_degree[i]['train']['MSE']}\")\n",
    "    print(f\"degree {i} test RMSE : {train_and_test_errors_at_given_degree[i]['test']['MSE']}\")\n",
    "    print(f\"degree {i} test RMSE : {train_and_test_errors_at_given_degree[i]['naive_MAE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe4c43",
   "metadata": {},
   "source": [
    "### show MAE, MSE, and RMSE and explain what this means for the predictions of the selected feature\n",
    "\n",
    "#### * high train error, high test error --> underfitting\n",
    "#### * low train error, high test error --> overfitting\n",
    "#### * low train error, low test error --> well fitted\n",
    "\n",
    "*RMSE*: \n",
    "- it penalizes the large errors more, it highlights models with fewer big mistakes\n",
    "- we square all the errors to make them non-negative and to penalize larger mistakes disproprtionately \n",
    "\t- big misses weigh more than small ones \t\n",
    "\n",
    "*MSE*: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbfa6d0",
   "metadata": {},
   "source": [
    "# Selecting the best degree by lowest RMSE (if there is a tie between one or more rows then we will switch to the MAE)\n",
    "\n",
    "### the order of selection in the tie-break selection process is RMSE, MAE \n",
    "### - RMSE to punish outliers (aka bigger mistakes/larger residuals)\n",
    "### - MAE as a secondary because absolute error is usful for punishing more smaller residulas and less sensitive to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca7a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (2221671364.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor i, deg in enumerate(polynomial_degrees):\u001b[39m\n    ^\n\u001b[31mTabError\u001b[39m\u001b[31m:\u001b[39m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e5449b2",
   "metadata": {},
   "source": [
    "## I am going to ask a TA about how to get the graph of the best degree here alonside with the prediction value that can be returned to the front end and have that prediction value plotted as a point on the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becafdc",
   "metadata": {},
   "source": [
    "$$\\mathbf{v}^\\top \\hat{\\mathbf{u}} ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a99713",
   "metadata": {},
   "source": [
    "# FINAL THINGS THAT NEED TO BE PUSHED TO THE FRONT END\n",
    "## 1) the best fit graph\n",
    "## 2) the 'RMSE at best degree' and 'MAE at best degree' bar charts\n",
    "## 3) the predicted value (accompanied by the name of the currency preferably)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
